---
title: "Binomial model - exercise"
output: 
  html_document: 
    theme: paper
    toc: yes
    toc_float: yes
  html_notebook: 
    toc: yes
    toc_float: yes
---

In this exercise, we fit a binomial regression model to the snow vole data.   
In our data set, called 'dati.mod.csv', the column 'CattSiNo' has a 0 for traps were no captures were recorded, and a 1 for traps were at least one capture occurred. This is our dependent variable.   
For the purpose of our exercise, we use the columns from 8 to 15 as explanatory variables.  

```{r captures-boxplot-varwidth}

dati.mod <- read.csv("data/dati.mod.csv")
head(dati.mod)
varexpl <- dati.mod[,8:15]
head(varexpl)

```


## Data exploration

First look at the dependent variable:

```{r}
hist(dati.mod$CattSiNo)
table(dati.mod$CattSiNo)
```

Now look at the explanatory variables:

```{r}
summary(varexpl)
```

Explore the pairwise relationship between the Y and X variables:

```{r}
with(dati.mod,
     boxplot(Incl ~ CattSiNo, main="Slope"))
with(dati.mod,
     boxplot(Alt ~ CattSiNo, main="Altitude"))
with(dati.mod,
     boxplot(copveg ~ CattSiNo, main="Veg cover"))
with(dati.mod,
     boxplot(NSpecie ~ CattSiNo, main="N species"))
with(dati.mod,
     boxplot(media.rocce ~ CattSiNo, main="Mean diam"))
with(dati.mod,
     boxplot(mediana.rocce ~ CattSiNo, main="Median diam"))
with(dati.mod,
     boxplot(sd.rocce ~ CattSiNo, main="SD diam"))
with(dati.mod,
     boxplot(Esp.tr ~ CattSiNo, main="Aspect"))
```

### Cleveland dotplot

```{r cleveland-dotplots}

par(mfrow=c(1,2))
dotchart(dati.mod$sd.rocce,
         ylab = "Order of observations",
         xlab = "SD diam", main = "")
dotchart(dati.mod$sd.rocce,
         groups = dati.mod$CattSiNo,
         ylab = "CattSiNo",
         xlab = "SD diam", main = "")
par(mfrow=c(1,1))

# eliminazione dell'outlier
subset(dati.mod, dati.mod$sd.rocce > 200)
dati.mod.new <- subset(dati.mod, dati.mod$sd.rocce < 200)

# trasformazione della variabile x
boxplot(dati.mod$sd.rocce)
boxplot(log(dati.mod$sd.rocce))
dati.mod.new2 <- cbind(dati.mod, logSD = log(dati.mod$sd.rocce))
dati.mod.new2 <- data.frame(dati.mod, logSD = log(dati.mod$sd.rocce))
head(dati.mod.new2)

```


## Analyse correlations

```{r}
cor(varexpl)
```


## Fit the base model

We can now fit our 'base model', i.e. the most complex model including all explanatory variables that are not too much correlated.


```{r}

fm1 <- glm(CattSiNo ~ Incl +
             Alt +
             copveg +
             # NSpecie +
             # media.rocce +
             mediana.rocce +
             sd.rocce +
             Esp.tr,
           family=binomial, data=dati.mod.new)
#, offset=Noccasioni)
summary(fm1)

hist(dati.mod.new$Ncatture)
fm1.pois <- glm(Ncatture ~ Incl +
             Alt +
             copveg +
             # NSpecie +
             # media.rocce +
             mediana.rocce +
             sd.rocce +
             Esp.tr,
           family=poisson, data=dati.mod.new)
#, offset=Noccasioni)
summary(fm1.pois)

```

Now, try to reduce the number of variables in the model - different models can be compared in terms of AIC:

```{r}
# UP TO YOU!!!

fm1.noexp <- glm(CattSiNo ~ Incl +
             Alt +
             copveg +
             # NSpecie +
             # media.rocce +
             mediana.rocce +
             sd.rocce, #+
             # Esp.tr,
           family=binomial, data=dati.mod.new)
#, offset=Noccasioni)
summary(fm1.noexp)


```


### Interpreting the results

If coefficient (logit) is positive, the effect of this predictor is positive and vice versa.

```{r}
fm2 <- glm(CattSiNo ~ #Incl +
             Alt +
             # copveg +
             # NSpecie +
             media.rocce, #+
             # mediana.rocce +
             # sd.rocce +
             # Esp.tr,
           family=binomial, data=dati.mod.new)
#, offset=Noccasioni)
summary(fm2)
```

### Plotting the results

The following is an example of a graph we can obtain using the termplot function (this is not necessarily the best model!!)

```{r}

par(mfrow=c(1,2))
termplot(fm2, se=TRUE, col.term = "red", col.se = "grey",
         ylabs = rep("odds ratio",2),
         main = c("Alt","Mean diam"), cex.main = 0.7)
par(mfrow=c(1,1))

```

```{r}
library(popbio)
logi.hist.plot(dati.mod.new$Alt,dati.mod.new$CattSiNo,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(dati.mod.new$media.rocce,dati.mod.new$CattSiNo,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(dati.mod.new$Esp.tr,dati.mod.new$CattSiNo,boxp=FALSE,type="hist",col="gray")

```


### Conversion to probability


```{r}
logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}
```

```{r}
logit2prob(coef(fm2))
```

The relationship between logit and probability is not linear, but of s-curve type.   
The coefficients in logit form can be be treated as in normal regression in terms of computing the y-value.   
Transform the logit of your y-value to probability to get a sense of the probability of the modeled event.

```{r}
predict.alt <- predict(fm2, data.frame(Alt=dati.mod.new$Alt,
                                       media.rocce=mean(dati.mod.new$media.rocce)),
                       type = "response")
tab <- data.frame(Alt=dati.mod.new$Alt,
           prob = predict.alt)
# tab
library(dplyr)
arrange(tab, Alt)
plot(arrange(tab, Alt))
```


```{r}
library(sjPlot)
plot_model(fm2, type = "pred")
```


```{r}
plot_model(fm2)
```


https://sebastiansauer.github.io/convert_logit2prob/
http://www.shizukalab.com/toolkits/plotting-logistic-regression-in-r






